---
title: "process_pxd_output"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

These instructions are for taking the monthly ProcXed output and processing to web format.

# prepare files for processing

* finalize ProcXed as usual, submit
* run ProcXed report "Web version"
* export as Excel
* delete first row and delete theme column
* save at: `F:/PHI/Publications/Governance/Pre Announcement/Outputs/2020/`
* use filename format, changing month/year: `ISD Forthcoming Publications Feb-20.xlsx`
* run ProcXed report - "Changes to Publication Date and Newly Added"
* export as Excel, delete first row
* save at: `F:/PHI/Publications/Governance/Pre Announcement/Outputs/2020/`
* use filename format, changing month/year: `ISD Dates Changed Feb-20.xlsx`

# set up R

* download the project from Github: https://github.com/graemegowans/pxd
  - click on Green `Clone or Download` > `Download Zip` > choose location > extract
  - you could also clone it if you are already using Git
* navigate to saved project location
* open project (`pxd.Rproj`) in RStudio
* in bottom right panel, click on `scripts` then `process_procxed_to_access.R`
* this will open in the main panel
* lines of code can be run by highlighting and pressing `Ctrl+Enter`

# process file

## install and load packages:

If this is the first time you have run this, you might need to install some packages. Copy the code below and paste into the Console - lower left panel in RStudio. You will only need to do this once.

```{r eval=FALSE}
# install packages
install.packages(magrittr)
install.packages(dplyr)
install.packages(readr)
install.packages(tidyr)
install.packages(stringr)
install.packages(janitor)
install.packages(readxl)
install.packages(lubridate)
install.packages(tidylog)
install.packages(fuzzyjoin)
install.packages(glue)
```

Every time you open a new R session, you have to load the packages using `library()` function:

```{r, warning = FALSE, message = FALSE}
# Load packages
library(magrittr)
library(dplyr)
library(readr)
library(tidyr)
library(stringr)
library(janitor)
library(readxl)
library(lubridate)
library(tidylog)
library(fuzzyjoin)
library(glue)
```

## define files/dates

You need to change the file paths to match the file you just created:

```{r}
#define file name and path
filename <- "Feb-20"
location <- file.path("//path", "to", "procxed", "output")
```

Usually location will be something like:

```{r}
location <- file.path("//F:", "PHI", "Publications", "Governance", "Pre Announcement", "Outputs", "2020")
```

Or you can define in full:

```{r}
location <- "F:/PHI/Publications/Governance/Pre Announcement/Outputs/2020/"
```

The `<-` symbol means assign - whatever is on the right side is assigned to the object on the left side - in this case an object called `location` which stores the path to the file. You can check by typing the name into the console to see what is stored in a variable:

```{r}
location
```

Add a date for when to show full or provisional dates on the webpage - e.g. for showing all dates up to the end of March:

```{r}
# Set limit for showing full date
date_limit <- "2020-04-01"
```

## load health topics

We have a running list of health topics for matching to publications, this is in the project folder (`data`, should have downloaded with project) - load this into RStudio as:

```{r}
# Get lookup table
lookup <- read_csv("data/ISD_lookup_topics.csv",
                   col_types = "cc")
```

Check that it looks ok by typing the name of the object in the console (`lookup`) or clicking the name of the object in the upper right `environment` panel

```{r}
lookup
```

## check new and changed dates

Can check if there are any issues with changed dates. Load (`read_xlsx()`) the output from the ProcXed report (new and changed dates) using the location and filename prepaerd earlier. Prepare new date columns for checking:

```{r warning = FALSE}
#load publications with changed dates
date_changed <- read_xlsx(glue("{location}/ISD Dates Changed ",
                               "{filename}.xlsx"), col_types = "text") %>% 
                clean_names() %>% 
                select(-producer_organisation, -statistics_type, -url_address)  

#prepare date columns for checking  
date_changed <- date_changed %>% 
                mutate(prev = if_else(is.na(ymd(previous_publication_date)), 
                                      dmy(paste0("01-", previous_publication_date)),
                                      ymd(previous_publication_date))) %>% 
                mutate(curr = if_else(is.na(ymd(current_publication_date)), 
                                      dmy(paste0("01-", current_publication_date)),
                                      ymd(current_publication_date)))
```

Can check changes to publications as:

```{r}
#has date within date limit changed?
date_changed %>% filter(prev < date_limit)

#is new date in the past?
date_changed %>% filter(curr < now())

#new pubs within date limit?
date_changed %>% filter(previous_publication_date == "NEWLY ADDED" &
                          current_publication_date < date_limit)
```

Any problems here might need followed up on.

## read forthcoming publications

Load (`read_xlsx()`) the list of forthcoming publications saved from ProcXed. This uses the location and filename that we stored earlier. It also renames columns to match the Access files and only keeps (`select()`) the listed columns:

```{r}
# Read the data - these are files from ProcXed report
# Rename column names for Access database
new_pubs <- read_xlsx(glue("{location}/ISD Forthcoming Publications ",
                           "{filename}.xlsx")) %>%
            rename(DatePublished = `Publication Date`, 
                   Title = `Publication Series`, 
                   Synopsis = `Synopsis`, 
                   ContactName = `Contact Details`) %>% 
            select(DatePublished, Title, Synopsis, ContactName)
```

Check that it looks ok by typing `new_pubs` into the console or clicking on it in upper right panel.

```{r}
new_pubs
```

## format publication dates

The publication dates are formatted to deal with finalized and provisional dates. This uses the `mutate` function to change the `DatePublished` column and some `lubridate` functions to check date formats. If the date is not in the format Day-Month-Year (e.g. Jan-20 is not), then paste a "01-" at the start and try again. All dates should now be in the format (YYYY-MM-DD), but those that started with provisional dates (MM-YYYY) will all be dated the first of that month.

Example:

```{r}
#generate test dates
final <- "27-Jan-2020"
prov <- "June-20"

#check if they are in the right format (can be parsed as DMY)
#this can
dmy(final)
#this one can't
dmy(prov)

#add "01-" to prov date and try again
prov2 <- paste0("01-", prov)
dmy(prov2)
```

Process the DatePublished column and show output:

```{r}
# Change all dates into dmy format
# If date doesn't parse as dmy (e.g. those in MM-YYY format) then add "01-" to the 
# start of the date and parse again, otherwise just parse
new_pubs %<>% 
  mutate(DatePublished = if_else(is.na(dmy(DatePublished)), 
                                    dmy(paste0("01-", DatePublished)),
                                    dmy(DatePublished)))
new_pubs
```

Then check if the `DatePublished` is before the date limit - if so, then keep it as it is. If not, then display it as the first of that month (`floor_date()` rounds to the nearest month):

```{r}
#example of rounding
test_dates <- dmy(c("27-Jan-2020", 
                    "28-Feb-2020",
                    "02-Mar-2020"))
floor_date(test_dates, unit = "month")
```

Round the publication dates as needed:

```{r}
# If DatePublished is before date_limit then show full date
# If not then show DatePublished as the first of the month
new_pubs %<>% 
  mutate(DatePublished = if_else(DatePublished < date_limit, 
                                    DatePublished, 
                                    floor_date(DatePublished, unit = "month")))
```

If the date is after the date limit then add "1" to a new column called `NotSet` - needed for website.

```{r}
# If publication date is after date_limit then add 1 to NotSet
# If publication date is before date_limit then leave blank
new_pubs %<>% 
  mutate(NotSet = if_else(DatePublished < date_limit, "", "1"))
```

Check if any of the publication dates up to the date limit are not Tuesday. These are probably typos and might need changed in ProcXed.

```{r}
#check all dates are Tuesday, show those that aren't
new_pubs %>% 
  mutate(day_of_week = wday(DatePublished, label = TRUE)) %>% 
  filter(DatePublished < date_limit & day_of_week != "Tue")
```

## clean up contact details

The website doesn't show email addresses so these are removed:

```{r}
# Remove the "\r\n" prefix from telephone numbers
# Remove email addresses
# Remove remaining "\r\n" text

new_pubs %<>% 
  mutate(ContactName = gsub("\r\ntel.", " tel.", ContactName)) %>% 
  mutate(ContactName = gsub("\r\ne-mail: (?:.*?)\r\n", "", ContactName)) %>% 
  mutate(ContactName = gsub("\r\n", " ", ContactName))
```

## add health topics

The `lookup` object is used to merge health topics to publication title. Uses a `fuzzy_left_join()` with `str_detect` to account for cases where there are dates in the title and therefore not a perfect match.

```{r}
# Remove brackets from (CAMHS) for matching
new_pubs %<>% mutate(Title = str_replace_all(Title, "\\(CAMHS\\)", "CAMHS"))

# Fuzzy join by detecting string name
new_pubs %<>% fuzzy_left_join(y = lookup, 
                              by = c("Title" = "TitleCode"), 
                              match_fun = str_detect)

# Replace brackets for CAMHS
new_pubs %<>% mutate(Title = str_replace_all(Title, "CAMHS", "\\(CAMHS\\)"))
```

The number of pubs in each area are counted - if there are any NA then these need added to the lookup file.

```{r}
# count numbers per topic
count(new_pubs, HealthTopic) %>% print(n = Inf)
```

If any are in `NA` group, you can see what they are:

```{r eval = FALSE}
######### MANUALLY FIX MISSING HealthTopic VALUES ##############
new_pubs %>% filter(is.na(HealthTopic)) %>% select(Title)
```

These can be added within R and a new version of the lookup file saved. Use the series only, not the edition (the part with the date), so that it doesn't need added every release:

```{r eval = FALSE}

# add this in to the lookup file and rerun from loading lookup
#new topics to add
topic_to_add <- tibble(TitleCode = "series to add",
                       HealthTopic = "Health-Topic")

#add rows
lookup <- bind_rows(lookup, topic_to_add)

#overwrite lookup table for next time
write_csv(lookup, "data/ISD_lookup_topics.csv")
```

You then need to rerun from section 3 (loading forthcoming pubs) to match these new health topics.

## clean up titles

Titles usually also have edition (e.g. October 2020 release) and these should be removed. This counts the number of commas in the title - if there is one, then the title is split here and only the first part kept. If there is more than 1, then the title is returned unchanged and a `title_flag` column added to highlight manual cleanup is needed.

```{r}
# Process the title to get rid of the edition (e.g. October 2020 release)
# If only 1 comma, then take text before comma
# If more than 1 comma, then flag title as needing manual clean up

new_pubs %<>% 
      mutate(comma_count = str_count(Title, ",")) %>%
      separate(Title, sep = ",", into = c("series", "edition"), remove = FALSE) %>%
      mutate(Title = if_else(comma_count == 1, series, Title),
              title_flag = if_else(comma_count > 1, "TRUE", "")) %>% 
      select(-c(comma_count, series, edition))
```

## general formatting

This adds extra columns for revised and rescheduled publications, adds html tags (<p> & </p>) to the synopsis, reformats the date and rearranges columns.

```{r}

# Add rescheduled_to and revised columns as NA
# these will need to be manually adjusted
# Add html tags for synopsis on website
# Change date format to dd/mm/yy
# Rearrange columns

new_pubs %<>% 
  mutate(RescheduledTo = NA, 
         Revised = NA, 
         Synopsis = glue("<p>{Synopsis}</p>"), 
         DatePublished = format(DatePublished, "%d/%m/%y")) %>% 
  select(title_flag, DatePublished, Title, HealthTopic, Synopsis, ContactName, 
         RescheduledTo, Revised, NotSet)
```

## adding rescheduled publications

Publications that have been rescheduled need two entries in the list to ensure that they appear at the original and new dates. The new date will already be in the ProcXed output, but the original date needs added back in. The this is added to the new_pubs object using `bind_rows()`. Remember to add a reason for delay in the synopsis.

```{r eval = FALSE}
# Remember to add reason for delay in Synopsis
# There should be an entry already for the rescheduled date
# ProcXed can run reports to show publications where dates 
# have changed to highlight these

rescheduled_pubs1 <- 
  tibble(DatePublished = "DD/MM/YYYY",
          Title = "title_here",
          HealthTopic = "topic_here",
          Synopsis = "<p>synopsis_here</p>",
          ContactName = paste0("analyst_1 tel. 123 456", 
                               "analyst_2 tel. 123 456"),
          RescheduledTo = "DD/MM/YYYY",
          Revised = NA, 
          NotSet = NA)

# Bind resched pubs
new_pubs <- bind_rows(new_pubs, rescheduled_pubs)
```

## remove duplicates

Weekly publications will have multiple entries per month but only want to display one of these on the website. To indentify these, make a key from Date, Title and Synopsis then extract the duplicated ones to check:

```{r}

# Make a key of DatePublished, Title and Synopsis
# Keep only the distinct ones
# Should be only weekly ED ones from later months

# This shows what will be removed, can check only ED weekly
dups <- new_pubs %>%
        mutate(dupkey = paste0(DatePublished, Title, Synopsis)) %>% 
        mutate(is_dup = duplicated(dupkey)) %>%
        filter(is_dup == TRUE)

dups
```

These can then be removed from `new_pubs`:

```{r}
# Remove these rows
new_pubs %<>%
  mutate(dupkey = paste0(DatePublished,Title, Synopsis)) %>%
  distinct(dupkey, .keep_all = TRUE) %>%
  select(-dupkey)
```

## save output

### csv file

The `new_pubs` object is then saved as a csv file to the same location as the ProcXed output. Use `write.csv()` as `write_csv()` was giving weird encoding issues in Access.

```{r eval = FALSE}
# Export file as .csv
# Use write.csv as write_csv sometimes gives weird encoding in access
write.csv(new_pubs, 
          glue("{location}/ISD_{filename}_processed_xl.csv"), 
          na = "",
          row.names = FALSE)
### END OF SCRIPT ###
```

### R script

You can save a dated version of the R script to this location as a record of changes that were made to e.g. rescheduled publications and health topics.

# Moving to Access format

Access can't import .csv files. After processing and exporting report, open csv file and:

* change any flagged titles as needed manually (to get rid of edition)
* delete the `title_flag` column
* check/fix any encoding issues - sometimes problems with symbols e.g. -, Â£, &, ", '
* save as .xls (Excel 97-03) for loading to Access
* you can delete the csv file now

Go to: `F:\PHI\Publications\Governance\Pre Announcement\Updating ISD Forthcoming Webpages`

* rename 'ForthcomingPubs.mdb' to 'ForthcomingPubs_[archive_date].mdb' (e.g. ForthcomingPubs_20190127.mdb)
* open Access
* click New (`Ctrl+ N`)
* make 'Blank database' (right hand side of screen)
* call it ForthcomingPubs and save to `Updating ISD Forthcoming Webpages` folder
* then: New > Import Table > select the .xls file made above (change file type to Excel if it doesn't appear) > select "has headers" > add to new Table > check it looks ok > add key automatically > choose name = "tblPubs"
* check rescheduled pubs are added and that all dates are formatted ok
* save and close
* upload using FileZilla FTP
* check website has updated


